# 会話生成手法の概要 (Generative Agents in LoCoMo)

本ドキュメントでは、`generate_conversations.py` におけるエージェントの会話生成プロセスについて、特に「記憶の想起 (Retrieval)」と「関係値の内省 (Relationship Reflection)」のメカニズムを中心に解説します。

## 1. 全体フロー

エージェントは単なる応答生成器ではなく、長期記憶と内省に基づく動的なコンテキストを持って発話を行います。

1. **コンテキスト構築**: 現在の状況、直近の会話、ペルソナに加え、**想起**された過去の記憶をプロンプトに統合。
2. **関係値の注入**: 前回のターン後に**内省**して更新された「相手への態度（関係値）」をプロンプトに反映。
3. **発話生成**: LLM (Gemini/GPT) により応答を生成。
4. **記憶と内省の更新**: 発話を記憶に保存し、次ターンのための関係値を再計算。

---

## 2. 想起 (Retrieval): 関連情報の抽出

エージェントは全ての過去ログをプロンプトに入れることはできないため、現在の状況に関連する重要な情報のみを「想起」して利用します。

### メカニズム

想起は `memory_stream` から以下のスコアに基づいてエビデンス（記憶の断片）をランク付けし、上位のものを抽出します。

$$ Score = \alpha \cdot Relevance + \beta \cdot Importance + \gamma \cdot Recency $$

1. **Relevance (関連性)**:
   - 現在の会話内容や生成された「高次質問 (High-Level Questions)」の埋め込みベクトルと、記憶の埋め込みベクトルのコサイン類似度。
2. **Importance (重要度)**:
   - その記憶がどれほど重要か（1-10 のスコア）。重要なイベントや事実は長く記憶に残ります。
3. **Recency (最新性)**:
   - 時間経過による減衰。指数関数的減衰 ($0.995^{hours}$) を用いて、最近の出来事を優先します。

### 会話生成への適用

- **セッション開始時**: 前回のセッションの要約や、重要なトピックを想起します。
- **会話中**: 直前の会話内容に関連する過去の事実やエピソードを動的に検索し、コンテキストとしてプロンプトに追加します。

---

## 3. 関係値生成 (Relationship Reflection): 態度の動的更新

会話の各ターン終了後、エージェントは「次の発話でどのような態度を取るべきか」を内省し、数値化された関係値ベクトルを更新します。

### 関係値ベクトル (7 段階評価: -3 〜 +3)

以下の 3 指標で関係性を評価します:

- **Power (力関係)**: 相手に対する優位性・支配性の度合い。高いほど話者が優位。
- **Intimacy (親密度)**: 相手との心理的距離の近さ、親しみの度合い。高いほど親密。
- **TaskOriented (タスク指向)**: 会話がどれだけ目的達成志向か。高いほどタスク集中、低いほど雑談・社交的。

### 生成プロセス (Post-turn Reflection)

発話が完了し、話者が交代するタイミングで以下の処理が行われます。

1. **高次質問 (HLQ) の生成**:
   - 直近のやり取りから「3 つの関係性次元それぞれを評価するための質問」を LLM に生成させます。
2. **証拠 (Evidence) の収集**:
   - 各 HLQ に基づいて、Memory Stream から**次元ごとに個別の**関連記憶（会話ログや過去の内省）を想起（Retrieve）します。
3. **LLM による評価**:
   - **入力**: ペルソナ、次元ごとの HLQ と証拠（Evidence）。
   - **出力**: JSON 形式のスコア（例: `{"Power": 1, "Intimacy": 2, "TaskOriented": 0}`）。
4. **状態の更新**:
   - 計算されたベクトルは `current_relationship_reflection` として保持され、**次のターンの発話生成プロンプト**に「相手への態度指示」として注入されます。

### 特徴

- **一方向性**: 常に「これから話す人 → 相手」のベクトルのみを計算・利用します。
- **セッション間の継承**: セッション終了時の最終値は保存され、次のセッションの初期値として引き継がれます。
- **次元別エビデンス**: 各次元（Power, Intimacy, TaskOriented）ごとに異なる証拠を選定し、より適切な評価を実現します。

---

## 4. プロンプトへの統合イメージ

最終的に LLM へ送られるプロンプトは以下のような構成になります。

```text
[System]
あなたは {Agent_A} です。{Agent_B} と会話しています。
ペルソナ: ...

[Context]
(想起された過去の重要な記憶)
...

[Relationship Reflection]
現在の {Agent_B} への態度:
- Power: -1 (やや従属的)
- Intimacy: +2 (親密)
- TaskOriented: 0 (中立)
この値を参考に、口調や反応を調整してください。

[Conversation]
B: こんにちは。
A: (ここで生成)
```

# 関係値内省 (Relationship Reflection) の生成フローと実例

本ドキュメントでは、`generate_conversations.py` における関係値内省 (Relationship Reflection) の生成プロセスを、実際の出力例を交えて詳細に解説します。

---

## 1. 概要

関係値内省は、会話中の各ターン終了後に「次に発話する話者が相手に対してどのような態度を取るべきか」を LLM に内省させ、3 次元のスコアとして数値化するプロセスです。

### 生成される関係値ベクトル（7 段階: -3 〜 +3）

| 次元                               | 説明                                     | 例                     |
| ---------------------------------- | ---------------------------------------- | ---------------------- |
| **Power（力関係）**                | 話者が相手に対して感じる優位性・影響力   | +2: 優位, -2: 従属的   |
| **Intimacy（親密度）**             | 話者が相手に対して感じる近しさ・好意     | +2: 親密, -2: 疎遠     |
| **TaskOriented（タスク指向対話）** | やり取りがタスク達成志向か雑談かの度合い | +2: 業務的, -2: 雑談的 |

---

## 2. 生成フロー全体像

```
┌─────────────────────────────────────────────────────────────────┐
│  ターン N の発話完了                                               │
│  （例: 高橋さおり「田中さん、おはようございます...」）               │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  Step 1: 直近メモリの収集                                         │
│  - memory_stream から直近10件の会話・内省を抽出                    │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  Step 2: 高レベル質問 (HLQ) の生成                                │
│  - 3つの関係性次元に対応する質問をLLMに生成させる                  │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  Step 3: 根拠 (Evidence) の選定                                   │
│  - HLQの埋め込みと記憶の埋め込みのコサイン類似度でランキング        │
│  - 重要度・最新性も加味してスコア化                                │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  Step 4: 関係値プロンプトの構築                                   │
│  - ペルソナ + HLQ + 根拠をまとめてLLMに送信                        │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  Step 5: 関係値ベクトルの生成                                     │
│  - LLMが {"Power": X, "Intimacy": Y, "TaskOriented": Z} を返す     │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  Step 6: 次ターンのプロンプトに注入（オプション）                  │
│  - 生成された関係値を次の発話生成時のプロンプトに含める            │
└─────────────────────────────────────────────────────────────────┘
```

---

## 3. 各ステップの詳細と実例

### Step 1: 直近メモリの収集

`memory_stream` または現在のセッションの発話履歴から、直近 10 件程度の会話・内省エントリを収集します。

**収集されるデータ例:**

```
[高橋 さおり] 田中さん、おはようございます。実は昨日の夜、目黒で面白い本を見つけて、ついつい読み耽ってしまいました。
[田中 ケンタ] 高橋さん、おはようございます！僕も先週の日曜日、地元で古いゲームを掘り出し始めてたら、気づいたら夕方になってましたよ。
[高橋 さおり] そういえば、私も十代の頃は秋葉原のパソコンショップで一日中パーツを眺めて、よく時間を忘れてたよ。
...
```

---

### Step 2: 高レベル質問 (HLQ) の生成

収集したメモリを入力として、LLM に 3 次元それぞれを評価するための質問を生成させます。

**入力プロンプト（日本語版）:**

```
次の直近のメモリ（会話・気づきを含む）のみを根拠として、以下の3つの関係性次元を観察するための高レベル質問を1つずつ作成してください:
1. Power（力関係）: どちらがより優位・影響力を持っているか？
2. Intimacy（親密度）: どれだけ親しく温かい関係か？
3. TaskOriented（タスク指向対話）: やり取りがどれだけタスク指向か？

各質問は【簡潔に（30文字程度）】、それぞれの次元を評価するのに役立つものにしてください。
出力は JSON 配列（要素は文字列）『のみ』で、ちょうど3件返してください。

直近メモリ:
- 田中さん、おはようございます。実は昨日の夜、目黒で面白い本を見つけて...
- 高橋さん、おはようございます！僕も先週の日曜日...
- そういえば、私も十代の頃は秋葉原のパソコンショップで...
```

**LLM 出力例:**

```json
[
  "発言者は相手に敬意を表しているか？",
  "個人的な出来事を共有できる関係か？",
  "会話の目的は業務遂行か雑談か？"
]
```

---

### Step 3: 根拠 (Evidence) の選定

生成された 3 つの HLQ を**検索クエリ**として使用し、直近メモリから関連性の高いエントリを選定します。

#### 3.1 処理フロー

```
┌─────────────────────────────────────────────────────────────────┐
│  HLQ（3つの質問）を埋め込みベクトル化                             │
│  例: "発言者は相手に敬意を表しているか？" → [0.12, -0.34, ...]    │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  各メモリエントリの埋め込みとHLQ埋め込みのコサイン類似度を計算      │
│  → 3つのHLQのうち最大の類似度を Relevance として採用              │
└─────────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────────┐
│  総合スコアでランキングし、上位エントリを根拠として選定            │
└─────────────────────────────────────────────────────────────────┘
```

#### 3.2 スコアリング計算式

各メモリエントリに対して以下のスコアを計算し、合計値でランキングします：

$$ Score = Relevance*{normalized} + Importance*{normalized} + Recency\_{normalized} $$

| 要素           | 計算方法                                  | 意味                                                  |
| -------------- | ----------------------------------------- | ----------------------------------------------------- |
| **Relevance**  | $\max_{q \in HLQ} \cos(\vec{q}, \vec{m})$ | 3 つの HLQ 埋め込みと記憶埋め込みの最大コサイン類似度 |
| **Importance** | 記憶保存時に付与 (1-10)                   | その記憶がどれほど重要か                              |
| **Recency**    | $0.995^{hours}$                           | 時間経過による指数減衰（最近ほど高い）                |

※ 各要素は 0〜1 の範囲に正規化 (min-max normalization) されます。

#### 3.3 HLQ を使った類似度計算の具体例

**Step 2 で生成された HLQ:**

```
Q1: "発言者は相手に敬意を表しているか？"       → Power 評価用
Q2: "個人的な出来事を共有できる関係か？"       → Intimacy 評価用
Q3: "会話の目的は業務遂行か雑談か？"          → TaskOriented 評価用
```

**直近メモリのエントリと類似度計算:**

| #   | メモリエントリ                                                                 | Q1 類似度 | Q2 類似度 | Q3 類似度 | Relevance (max) |
| --- | ------------------------------------------------------------------------------ | --------- | --------- | --------- | --------------- |
| 1   | [高橋] 田中さん、おはようございます。実は昨日の夜、目黒で面白い本を見つけて... | 0.72      | **0.85**  | 0.61      | **0.85**        |
| 2   | [田中] 高橋さん、おはようございます！僕も先週の日曜日、地元で古いゲームを...   | **0.78**  | 0.82      | 0.58      | **0.82**        |
| 3   | [高橋] そういえば、私も十代の頃は秋葉原のパソコンショップで...                 | 0.65      | **0.79**  | 0.55      | **0.79**        |
| 4   | [田中] 僕も高校生の時、地元の電気屋で部品漁って自作 PC 組んだら...             | 0.63      | **0.81**  | 0.52      | **0.81**        |

**解釈:**

- **エントリ 1**は「目黒で面白い本を見つけて...」という**個人的な出来事の共有**が含まれるため、Q2（Intimacy 評価用）との類似度が最も高い
- **エントリ 2**は「高橋さん」という**敬称使用**と個人的な話題の共有があり、Q1・Q2 両方と高い類似度
- すべてのエントリが**雑談的**なため、Q3（業務目的かどうか）との類似度は相対的に低い

#### 3.4 総合スコアによるランキング

```
エントリ1: Relevance=0.85, Importance=6/10, Recency=0.99 → 正規化後合計: 2.65
エントリ2: Relevance=0.82, Importance=5/10, Recency=0.98 → 正規化後合計: 2.42
エントリ3: Relevance=0.79, Importance=5/10, Recency=0.97 → 正規化後合計: 2.31
...
```

#### 3.5 選定された根拠（上位エントリ）

文字数制限（約 2200 文字）に収まる範囲で上位エントリを番号付きで採用：

```
1. [高橋 さおり] 田中さん、おはようございます。実は昨日の夜、目黒で面白い本を見つけて、ついつい読み耽ってしまいました。
2. [田中 ケンタ] 高橋さん、おはようございます！僕も先週の日曜日、地元で古いゲームを掘り出し始めてたら、気づいたら夕方になってましたよ。
3. [高橋 さおり] そういえば、私も十代の頃は秋葉原のパソコンショップで一日中パーツを眺めて、よく時間を忘れてたよ。
...
```

**なぜこれらが選ばれたか:**

- **敬称使用**（「田中さん」「高橋さん」）→ Q1（敬意・Power）評価に有用
- **個人的エピソードの共有**（趣味の話）→ Q2（親密度・Intimacy）評価に有用
- **業務外の話題**→ Q3（タスク指向）評価に有用（雑談であることを示す）

---

### Step 4: 関係値プロンプトの構築

HLQ と根拠を組み合わせ、ペルソナ情報とともに LLM へ送信するプロンプトを構築します。

**実際のプロンプト例（田中 → 高橋）:**

```
以下の高レベル質問と番号付き根拠に基づいて、田中 ケンタ から 高橋 さおり への関係値を 7 段階（-3〜+3 の整数）で評価してください。
評価する指標は3つです:
- Power: 力関係（田中 ケンタ が 高橋 さおり に対して自分がより優位/影響力があると感じる度合い。高いほど 田中 ケンタ が優位と感じる）
- Intimacy: 親密度（田中 ケンタ が 高橋 さおり に対して感じる近しさ・好意の度合い。高いほど親しい）
- TaskOriented: タスク指向対話（やり取りがどれだけタスク指向か。高いほどタスク志向、低いほど雑談・社交的）

キャラクターのペルソナ:
- 田中 ケンタ: 入社2年目の若手エンジニア。技術への好奇心が旺盛で、エネルギーに満ち溢れている。経験不足を熱意と行動力でカバーしようとする努力家。先輩である高橋を尊敬している。
- 高橋 さおり: 経験豊富なシニアエンジニア。論理的かつ合理的で、感情よりも事実や効率を重視するプロフェッショナル。部下に対しては厳格だが、成長を願う面倒見の良さも秘めている。

出力は JSON オブジェクトのみ（英語キー名厳守）: {"Power":-3..+3,"Intimacy":-3..+3,"TaskOriented":-3..+3}。JSON 以外の文章は書かないでください。

高レベル質問:
- 発言者は相手に敬意を表しているか？
- 個人的な出来事を共有できる関係か？
- 会話の目的は業務遂行か雑談か？

根拠（番号付き）:
1. [高橋 さおり] 田中さん、おはようございます。実は昨日の夜、目黒で面白い本を見つけて、ついつい読み耽ってしまいました。
2. [田中 ケンタ] 高橋さん、おはようございます！僕も先週の日曜日、地元で古いゲームを掘り出し始めてたら、気づいたら夕方になってましたよ。
```

---

### Step 5: 関係値ベクトルの生成

LLM がプロンプトに基づいて関係値を評価し、JSON で返します。

**LLM 出力例（田中 → 高橋）:**

```json
{ "Power": -2, "Intimacy": 1, "TaskOriented": -2 }
```

**解釈:**

- **Power: -2** → 田中は高橋に対して自分が従属的だと感じている（先輩後輩関係）
- **Intimacy: +1** → やや親しみを感じている（趣味の話で打ち解けている）
- **TaskOriented: -2** → 会話は雑談的（業務の話ではなく趣味の共有）

---

### Step 6: 次ターンのプロンプトへの注入

`--relationship-reflection-no-inject` オプションが**指定されていない**場合、生成された関係値は次の発話生成プロンプトに注入されます。

**注入後のプロンプト例:**

```
あなたは 田中 ケンタ です。高橋 さおり と会話しています。
ペルソナ: 入社2年目の若手エンジニア...

【関係値内省】
現在の 高橋 さおり への態度:
- Power: -2（従属的）
- Intimacy: +1（やや親密）
- TaskOriented: -2（雑談的）
この値を参考に、口調や反応を自然に調整してください。

会話履歴:
高橋 さおり: 私も十代の頃は秋葉原のパソコンショップで...
田中 ケンタ: (ここで生成)
```

---

## 4. ターン毎の関係値推移の例

セッション 1 での関係値の推移（`rr_prompt_trace_session_1.jsonl` より抽出）:

| ターン | 方向        | Power | Intimacy | TaskOriented | 主な根拠           |
| ------ | ----------- | ----- | -------- | ------------ | ------------------ |
| 0      | 田中 → 高橋 | -2    | 0        | -1           | 挨拶のみ           |
| 1      | 高橋 → 田中 | +1    | +1       | -2           | 趣味の話開始       |
| 2      | 田中 → 高橋 | -2    | +1       | -2           | 共通の趣味発見     |
| 3      | 高橋 → 田中 | +2    | +1       | -1           | 助言的発言         |
| 4      | 田中 → 高橋 | -2    | +2       | -2           | 憧れの表明         |
| 5      | 高橋 → 田中 | +2    | +2       | -1           | 経験の共有・励まし |

**観察:**

- **Power**: 高橋 → 田中は常に正（優位）、田中 → 高橋は常に負（従属）→ 先輩後輩関係が反映
- **Intimacy**: ターンが進むにつれ両者とも上昇 → 趣味の共有で親密度が増加
- **TaskOriented**: 終始負の値 → この会話は雑談的であることを正しく捉えている

---

## 5. 出力ファイル

関係値生成プロセスのトレースは以下のファイルに出力されます:

### `rr_prompt_trace_session_{N}.jsonl`

各ターンのプロンプト構成要素を JSONL 形式で記録:

```json
{
  "time": "2025-12-10T10:57:15.009376",
  "session_idx": 1,
  "language": "ja",
  "hlq_list": [
    "発言者は相手に敬意を表しているか？",
    "個人的な出来事を共有できる関係か？",
    "会話の目的は業務遂行か雑談か？"
  ],
  "hlq_block": "- 発言者は相手に敬意を表しているか？\n- 個人的な出来事を共有できる関係か？\n- 会話の目的は業務遂行か雑談か？",
  "evidence_numbered": ["1. [高橋 さおり] 田中さん、おはようございます..."],
  "evidence_block": "1. [高橋 さおり] 田中さん、おはようございます...",
  "direction": "b_to_a",
  "src": "田中 ケンタ",
  "dst": "高橋 さおり",
  "src_persona": "入社2年目の若手エンジニア...",
  "dst_persona": "経験豊富なシニアエンジニア...",
  "prompt": "(完全なプロンプト文字列)"
}
```

### `agent_a.json` / `agent_b.json`

エージェントデータ内の `session_{N}_relationship_reflection_turns` に結果を保存:

```json
{
  "session_1_relationship_reflection_turns": [
    {
      "turn": 0,
      "rr": {
        "a_to_b": {"Power": 1, "Intimacy": 0, "TaskOriented": 0},
        "b_to_a": {"Power": -2, "Intimacy": 0, "TaskOriented": -1},
        "by_speaker": {
          "高橋 さおり": {"toward": "田中 ケンタ", "vector": {...}},
          "田中 ケンタ": {"toward": "高橋 さおり", "vector": {...}}
        }
      },
      "next_speaker": "田中 ケンタ",
      "injected": true
    },
    ...
  ]
}
```

---

## 6. 可視化

生成された関係値は `scripts/plot_relationship_reflection.py` で可視化できます:

```bash
# 単一ファイルの推移をプロット
python scripts/plot_relationship_reflection.py out/test/agent_a.json -o rr_plot.png

# 注入あり/なしの比較
python scripts/plot_relationship_reflection.py \
    out/with_inject/agent_a.json \
    out/without_inject/agent_a.json \
    --labels "注入あり" "注入なし" \
    -o comparison.png

# CSVエクスポート
python scripts/plot_relationship_reflection.py out/test/agent_a.json --csv
```

---

## 7. 関連ファイル

| ファイル                                      | 役割                                                 |
| --------------------------------------------- | ---------------------------------------------------- |
| `generative_agents/memory_utils.py`           | 関係値生成ロジック (`get_relationship_reflection()`) |
| `generative_agents/generate_conversations.py` | 会話生成メインループ、関係値の呼び出しと注入         |
| `scripts/plot_relationship_reflection.py`     | 関係値推移の可視化                                   |
| `GENERATION_METHOD.md`                        | 全体フローの概要                                     |

---

## 8. 設定オプション

| オプション                             | 説明                                                         |
| -------------------------------------- | ------------------------------------------------------------ |
| `--relationship-reflection`            | 関係値内省を有効化                                           |
| `--relationship-reflection-every-turn` | 各ターン後に関係値を計算（デフォルトはセッション開始時のみ） |
| `--relationship-reflection-no-inject`  | 計算はするがプロンプトに注入しない（実験用）                 |
